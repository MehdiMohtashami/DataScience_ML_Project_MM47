نتایج ارزیابی مدل‌ها:
                       Model       RMSE        MAE        R²   Time (s)
5  Support Vector Regression  66.723633  43.498991  0.491029  43.632943
3              Random Forest  68.374081  46.638710  0.465538   1.264356
4          Gradient Boosting  68.522440  48.931450  0.463216   2.177393
1           Ridge Regression  81.098618  56.573180  0.248098   0.044493
0          Linear Regression  81.098905  56.573895  0.248093   0.056816
2           Lasso Regression  81.099736  56.573103  0.248078   0.231383

بهترین مدل ذخیره شد: SVR(C=100, gamma=0.1) با R² = 0.4910

بارگذاری داده‌ها...
مدیریت داده‌های گمشده...
مدیریت داده‌های پرت...
مهندسی ویژگی‌ها...
تقسیم داده‌ها...
تعداد داده‌های آموزش: 33093
تعداد داده‌های آزمون: 8661
تعریف خط لوله پیش‌پردازش...
تعریف مدل‌ها برای مقایسه...
آموزش و ارزیابی مدل‌ها...

آموزش مدل: Random Forest

آموزش مدل: XGBoost

آموزش مدل: LightGBM
[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001040 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Info] Total Bins 1349
[LightGBM] [Info] Number of data points in the train set: 33093, number of used features: 44
[LightGBM] [Info] Start training from score 95.398483

آموزش مدل: Gradient Boosting

نتایج ارزیابی مدل‌ها:
               Model       RMSE        MAE        R²   Time (s)
3  Gradient Boosting  24.081871  14.999099  0.911187  13.714327
2           LightGBM  24.303653  14.982497  0.909544   1.180610
1            XGBoost  24.624782  15.236037  0.907137   2.283965
0      Random Forest  24.821401  15.409309  0.905648   4.667866

تنظیم هیپرپارامترها برای Gradient Boosting...
Fitting 3 folds for each of 162 candidates, totalling 486 fits

بهترین پارامترها: {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 500}
بهترین امتیاز R² در اعتبارسنجی: 0.8961
R² نهایی روی داده آزمون: 0.9112

ذخیره بهترین مدل...
بهترین مدل (Gradient Boosting) با دقت 0.9112 ذخیره شد.

تحلیل اهمیت ویژگی‌ها...

ایجاد نمودار مقایسه مدل‌ها...
\نمونه‌ای از پیش‌بینی‌ها...

مقایسه پیش‌بینی مدل‌ها برای 10 نمونه تصادفی:
       Actual  Gradient Boosting  Random Forest     XGBoost    LightGBM
38338    98.0         104.432901        104.835  100.995972  102.733718
35303   104.0         123.480131        114.020  149.752029  147.499492
38323    43.0          49.653654         45.700   50.406273   49.873735
38473    74.0          72.375966         80.265   79.070602   87.797751
35611   295.0         280.493187        278.285  290.868622  279.961904
36234    88.0          69.853276         63.110   63.298615   65.848476
36186   169.0         175.534956        176.040  157.107498  177.030439
38765    87.0          80.105160         83.405   85.855064   89.820966
38231    54.0          63.745467         64.480   64.021133   64.217362
35979    88.0         102.457436         89.700   99.570061   92.840026

ذخیره تمام مدل‌ها...
تمام مدل‌ها با موفقیت ذخیره شدند.

گزارش نهایی:
- بهترین مدل: Gradient Boosting با دقت R² = 0.9112
- تعداد ویژگی‌ها: 46
- تعداد داده‌های آموزش: 33093
- تعداد داده‌های آزمون: 8661
- مهم‌ترین ویژگی: avg_last_3h

پروژه با موفقیت به پایان رسید!

Process finished with exit code 0

# # import pandas as  pd
# # df_dataset= pd.read_csv('Autism-Adult-Data.csv')
# # #For Autism-Adult-Data.csv
# # print('#'*20,'For Autism-Adult-Data.csv', '#'*20)
# # print(df_dataset.describe(include='all').to_string())
# # print(df_dataset.shape)
# # print(df_dataset.columns)
# # print(df_dataset.info)
# # print(df_dataset.dtypes)
# # print(df_dataset.isna().sum())
# # print(df_dataset.head(10).to_string())
# # print('='*70)
# # Import necessary libraries
# import pandas as pd
# import numpy as np
# import matplotlib.pyplot as plt
# import seaborn as sns
# from sklearn.model_selection import train_test_split
# from sklearn.preprocessing import StandardScaler, LabelEncoder
# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
# from sklearn.linear_model import LogisticRegression
# from sklearn.neighbors import KNeighborsClassifier
# from sklearn.svm import SVC
# from sklearn.tree import DecisionTreeClassifier
# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
# from xgboost import XGBClassifier
# import warnings
#
# warnings.filterwarnings('ignore')
#
# # Load the dataset
# df = pd.read_csv('Autism-Adult-Data.csv')
#
# # Initial data analysis
# print("=" * 50)
# print("INITIAL DATA ANALYSIS")
# print("=" * 50)
# print(f"Dataset Shape: {df.shape}")
# print("\nData Types:")
# print(df.dtypes)
# print("\nMissing Values:")
# print(df.isna().sum())
# print("\nFirst 10 Rows:")
# print(df.head(10))
#
# # Handle missing values
# print("\n" + "=" * 50)
# print("HANDLING MISSING VALUES")
# print("=" * 50)
#
# # Fill age with median
# age_median = df['age'].median()
# df['age'].fillna(age_median, inplace=True)
# print(f"Filled {df['age'].isna().sum()} missing values in 'age' with median: {age_median}")
#
# # Fill categorical columns with 'Unknown'
# df['ethnicity'].fillna('Unknown', inplace=True)
# df['relation'].fillna('Unknown', inplace=True)
# print(f"Filled missing values in 'ethnicity' and 'relation' with 'Unknown'")
#
# # Check if any missing values remain
# print(f"Remaining missing values: {df.isna().sum().sum()}")
#
# # Data Preprocessing
# print("\n" + "=" * 50)
# print("DATA PREPROCESSING")
# print("=" * 50)
#
# # Remove unnecessary columns (age_desc has only one value)
# df.drop('age_desc', axis=1, inplace=True)
# print("Removed 'age_desc' column")
#
# # Convert binary categorical columns to numerical
# binary_cols = ['gender', 'jundice', 'austim', 'used_app_before', 'Class/ASD']
# le = LabelEncoder()
# for col in binary_cols:
#     df[col] = le.fit_transform(df[col])
#     print(f"Converted {col} to numerical values")
#
# # One-Hot Encoding for other categorical columns
# categorical_cols = ['ethnicity', 'contry_of_res', 'relation']
# df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)
# print(f"Applied One-Hot Encoding to: {categorical_cols}")
#
# print(f"Final dataset shape: {df.shape}")
#
# # Exploratory Data Analysis (EDA)
# print("\n" + "=" * 50)
# print("EXPLORATORY DATA ANALYSIS (EDA)")
# print("=" * 50)
#
# # Set style for plots
# sns.set_style("whitegrid")
# plt.figure(figsize=(12, 8))
#
# # 1. Age Distribution
# plt.subplot(2, 2, 1)
# sns.histplot(df['age'], bins=30, kde=True)
# plt.title('Age Distribution')
# plt.xlabel('Age')
#
# # 2. Class Distribution
# plt.subplot(2, 2, 2)
# class_counts = df['Class/ASD'].value_counts()
# plt.pie(class_counts, labels=['No', 'Yes'], autopct='%1.1f%%', startangle=90)
# plt.title('Class Distribution (ASD)')
#
# # 3. Correlation Heatmap (first 20 features for readability)
# plt.subplot(2, 2, 3)
# corr_matrix = df.corr().abs()
# sns.heatmap(corr_matrix.iloc[:20, :20], cmap='coolwarm', center=0)
# plt.title('Correlation Matrix (First 20 Features)')
#
# # 4. Boxplot of Age by ASD Class
# plt.subplot(2, 2, 4)
# sns.boxplot(x=df['Class/ASD'], y=df['age'])
# plt.title('Age Distribution by ASD Class')
# plt.xticks([0, 1], ['No', 'Yes'])
#
# plt.tight_layout()
# plt.show()
#
# # Additional EDA - Question Scores Analysis
# plt.figure(figsize=(15, 10))
# question_cols = [f'A{i}_Score' for i in range(1, 11)]
# asd_yes = df[df['Class/ASD'] == 1]
# asd_no = df[df['Class/ASD'] == 0]
#
# for i, col in enumerate(question_cols, 1):
#     plt.subplot(3, 4, i)
#     yes_mean = asd_yes[col].mean()
#     no_mean = asd_no[col].mean()
#     plt.bar(['No ASD', 'ASD'], [no_mean, yes_mean])
#     plt.title(f'{col} Mean Score')
#     plt.ylabel('Mean Score')
#
# plt.tight_layout()
# plt.show()
#
# # Prepare data for modeling
# X = df.drop('Class/ASD', axis=1)
# y = df['Class/ASD']
#
# # Split the data
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
#
# # Standardize the features
# scaler = StandardScaler()
# X_train_scaled = scaler.fit_transform(X_train)
# X_test_scaled = scaler.transform(X_test)
#
# print(f"Training set: {X_train.shape}, Test set: {X_test.shape}")
# print(f"Class distribution in training set: {np.bincount(y_train)}")
# print(f"Class distribution in test set: {np.bincount(y_test)}")
#
# # Model Training and Evaluation
# print("\n" + "=" * 50)
# print("MODEL TRAINING AND EVALUATION")
# print("=" * 50)
#
# models = {
#     "Logistic Regression": LogisticRegression(random_state=42, class_weight='balanced'),
#     "K-Nearest Neighbors": KNeighborsClassifier(),
#     "Support Vector Machine": SVC(random_state=42, class_weight='balanced'),
#     "Decision Tree": DecisionTreeClassifier(random_state=42, class_weight='balanced'),
#     "Random Forest": RandomForestClassifier(random_state=42, class_weight='balanced'),
#     "Gradient Boosting": GradientBoostingClassifier(random_state=42),
#     "XGBoost": XGBClassifier(random_state=42, eval_metric='logloss')
# }
#
# results = {}
# for name, model in models.items():
#     # Train the model
#     model.fit(X_train_scaled, y_train)
#
#     # Make predictions
#     y_pred = model.predict(X_test_scaled)
#
#     # Calculate accuracy
#     acc = accuracy_score(y_test, y_pred)
#     results[name] = acc
#
#     # Print results
#     print(f"\n{name}")
#     print("-" * len(name))
#     print(f"Accuracy: {acc:.4f}")
#     print("Classification Report:")
#     print(classification_report(y_test, y_pred))
#
#     # Plot confusion matrix
#     plt.figure(figsize=(5, 4))
#     cm = confusion_matrix(y_test, y_pred)
#     sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
#                 xticklabels=['No ASD', 'ASD'],
#                 yticklabels=['No ASD', 'ASD'])
#     plt.title(f'Confusion Matrix - {name}')
#     plt.ylabel('True Label')
#     plt.xlabel('Predicted Label')
#     plt.show()
#
# # Compare model performance
# print("\n" + "=" * 50)
# print("MODEL COMPARISON")
# print("=" * 50)
#
# # Create a DataFrame for results comparison
# results_df = pd.DataFrame(list(results.items()), columns=['Model', 'Accuracy'])
# results_df = results_df.sort_values('Accuracy', ascending=False).reset_index(drop=True)
#
# print("Models ranked by accuracy:")
# print(results_df)
#
# # Plot model comparison
# plt.figure(figsize=(10, 6))
# sns.barplot(x='Accuracy', y='Model', data=results_df, palette='viridis')
# plt.title('Model Comparison - Accuracy Scores')
# plt.xlim(0, 1)
# plt.xlabel('Accuracy')
# plt.tight_layout()
# plt.show()
#
# # Feature importance for the best tree-based model
# best_model_name = results_df.iloc[0]['Model']
# best_model = models[best_model_name]
#
# if hasattr(best_model, 'feature_importances_'):
#     print(f"\nFeature Importance from {best_model_name}:")
#     feature_importance = pd.DataFrame({
#         'feature': X.columns,
#         'importance': best_model.feature_importances_
#     })
#     feature_importance = feature_importance.sort_values('importance', ascending=False).head(10)
#
#     plt.figure(figsize=(10, 6))
#     sns.barplot(x='importance', y='feature', data=feature_importance, palette='magma')
#     plt.title(f'Top 10 Feature Importance - {best_model_name}')
#     plt.tight_layout()
#     plt.show()
#
#     print(feature_importance)
#
# print("\n" + "=" * 50)
# print("CONCLUSION")
# print("=" * 50)
# print(f"Best performing model: {best_model_name} with accuracy: {results[best_model_name]:.4f}")
#
# # Ø§Ø¯Ø§Ù…Ù‡ Ú©Ø¯ Ø¨Ø¹Ø¯ Ø§Ø² Ø¨Ø®Ø´ Ù…Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ
#
# import joblib
# import os
#
# # Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§
# if not os.path.exists('models'):
#     os.makedirs('models')
#
# # Ø°Ø®ÛŒØ±Ù‡ Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§
# for name, model in models.items():
#     joblib.dump(model, f'models/{name.replace(" ", "_").lower()}_model.joblib')
#     print(f"Ù…Ø¯Ù„ {name} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
#
# # Ø°Ø®ÛŒØ±Ù‡ scaler
# joblib.dump(scaler, 'models/scaler.joblib')
# print("Scaler Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
#
# # Ø°Ø®ÛŒØ±Ù‡ Ù„ÛŒØ³Øª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± Ø¢ÛŒÙ†Ø¯Ù‡)
# feature_names = list(X.columns)
# joblib.dump(feature_names, 'models/feature_names.joblib')
# print("Ù„ÛŒØ³Øª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
#
# # Ø§ÛŒØ¬Ø§Ø¯ ÛŒÚ© Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§
# model_info = {
#     'models': {name: model for name, model in models.items()},
#     'scaler': scaler,
#     'feature_names': feature_names,
#     'results': results
# }
#
# # Ø°Ø®ÛŒØ±Ù‡ Ù‡Ù…Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø± ÛŒÚ© ÙØ§ÛŒÙ„
# joblib.dump(model_info, 'models/all_models_info.joblib')
# print("Ù‡Ù…Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¯Ø± ÛŒÚ© ÙØ§ÛŒÙ„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
#
# print("\n" + "=" * 50)
# print("Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡:")
# print("=" * 50)
# for name in models.keys():
#     print(f"- {name.replace('_', ' ').title()}")
#
# # Ú©Ø¯ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¯Ø± Ø¢ÛŒÙ†Ø¯Ù‡
# print("\n" + "=" * 50)
# print("Ù†Ø­ÙˆÙ‡ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¯Ø± Ø¢ÛŒÙ†Ø¯Ù‡:")
# print("=" * 50)
# print("""
# # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒÚ© Ù…Ø¯Ù„ Ø®Ø§Øµ
# model = joblib.load('models/gradient_boosting_model.joblib')
#
# # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ scaler
# scaler = joblib.load('models/scaler.joblib')
#
# # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù‡Ù…Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª
# all_models = joblib.load('models/all_models_info.joblib')
# gradient_boosting_model = all_models['models']['Gradient Boosting']
# """)
#
#
# # Ø§ÛŒØ¬Ø§Ø¯ ÛŒÚ© ØªØ§Ø¨Ø¹ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¢ÛŒÙ†Ø¯Ù‡
# def predict_asd(new_data, model_name='Gradient Boosting'):
#     """
#     ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
#     """
#     # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ùˆ scaler
#     model = joblib.load(f'models/{model_name.replace(" ", "_").lower()}_model.joblib')
#     scaler = joblib.load('models/scaler.joblib')
#     feature_names = joblib.load('models/feature_names.joblib')
#
#     # Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
#     new_data_scaled = scaler.transform(new_data)
#
#     # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
#     predictions = model.predict(new_data_scaled)
#     prediction_proba = model.predict_proba(new_data_scaled) if hasattr(model, "predict_proba") else None
#
#     return predictions, prediction_proba
#
#
# # ØªØ³Øª ØªØ§Ø¨Ø¹ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø§ ÛŒÚ© Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª
# sample_data = X_test.iloc[:1]
# prediction, probability = predict_asd(sample_data)
# print(f"\nØªØ³Øª Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÙˆÛŒ ÛŒÚ© Ù†Ù…ÙˆÙ†Ù‡: {prediction[0]} (Ú©Ù„Ø§Ø³ ÙˆØ§Ù‚Ø¹ÛŒ: {y_test.iloc[0]})")
# if probability is not None:
#     print(f"Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª: {probability[0]}")
# import pandas as pd
# import numpy as np
# import matplotlib.pyplot as plt
# import seaborn as sns
# from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
# from sklearn.preprocessing import StandardScaler
# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, \
#     f1_score
# import joblib
# import warnings
#
# warnings.filterwarnings('ignore')
#
# # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡ Ø§ØµÙ„ÛŒ
# df = pd.read_csv('Autism-Adult-Data.csv')
#
# # Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ (Ù…Ø´Ø§Ø¨Ù‡ Ù‚Ø¨Ù„)
# df['age'].fillna(df['age'].median(), inplace=True)
# df['ethnicity'].fillna('Unknown', inplace=True)
# df['relation'].fillna('Unknown', inplace=True)
# df.drop('age_desc', axis=1, inplace=True)
#
# # ØªØ¨Ø¯ÛŒÙ„ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ú©ÛŒÙÛŒ Ø¨Ù‡ Ø¹Ø¯Ø¯ÛŒ
# from sklearn.preprocessing import LabelEncoder
#
# binary_cols = ['gender', 'jundice', 'austim', 'used_app_before', 'Class/ASD']
# le = LabelEncoder()
# for col in binary_cols:
#     df[col] = le.fit_transform(df[col])
#
# # One-Hot Encoding
# categorical_cols = ['ethnicity', 'contry_of_res', 'relation']
# df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)
#
# # ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
# X = df.drop('Class/ASD', axis=1)
# y = df['Class/ASD']
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
#
# # Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ
# scaler = StandardScaler()
# X_train_scaled = scaler.fit_transform(X_train)
# X_test_scaled = scaler.transform(X_test)
#
# print("=" * 60)
# print("Ø¨Ø±Ø±Ø³ÛŒ Ø¬Ø§Ù…Ø¹ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡")
# print("=" * 60)
#
# # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡
# models_to_load = [
#     'logistic_regression_model.joblib',
#     'k-nearest_neighbors_model.joblib',
#     'support_vector_machine_model.joblib',
#     'decision_tree_model.joblib',
#     'random_forest_model.joblib',
#     'gradient_boosting_model.joblib',
#     'xgboost_model.joblib'
# ]
#
# models = {}
# for model_file in models_to_load:
#     try:
#         model_name = model_file.replace('_model.joblib', '').replace('_', ' ').title()
#         models[model_name] = joblib.load(f'models/{model_file}')
#         print(f"âœ… Ù…Ø¯Ù„ {model_name} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
#     except:
#         print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ {model_file}")
#
# print("\n" + "=" * 60)
# print("Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡ ØªØ³Øª")
# print("=" * 60)
#
# results = {}
# for name, model in models.items():
#     # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡ ØªØ³Øª
#     y_pred = model.predict(X_test_scaled)
#
#     # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
#     acc = accuracy_score(y_test, y_pred)
#     prec = precision_score(y_test, y_pred)
#     rec = recall_score(y_test, y_pred)
#     f1 = f1_score(y_test, y_pred)
#
#     results[name] = {
#         'accuracy': acc,
#         'precision': prec,
#         'recall': rec,
#         'f1_score': f1
#     }
#
#     print(f"\n{name}:")
#     print(f"  Ø¯Ù‚Øª: {acc:.4f}")
#     print(f"  precision: {prec:.4f}")
#     print(f"  recall: {rec:.4f}")
#     print(f"  F1-score: {f1:.4f}")
#     print("  " + "-" * 30)
#
# # Ø§ÛŒØ¬Ø§Ø¯ DataFrame Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù†ØªØ§ÛŒØ¬
# results_df = pd.DataFrame.from_dict(results, orient='index')
# results_df = results_df.sort_values('accuracy', ascending=False)
#
# print("\n" + "=" * 60)
# print("Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ù‚Øª")
# print("=" * 60)
# print(results_df[['accuracy', 'f1_score']].round(4))
#
# # Ø¨Ø±Ø±Ø³ÛŒ overfitting Ø¨Ø§ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡ train Ùˆ test
# print("\n" + "=" * 60)
# print("Ø¨Ø±Ø±Ø³ÛŒ Overfitting (Ø§Ø®ØªÙ„Ø§Ù Ø¹Ù…Ù„Ú©Ø±Ø¯ train/test)")
# print("=" * 60)
#
# overfitting_results = {}
# for name, model in models.items():
#     # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡ train
#     y_train_pred = model.predict(X_train_scaled)
#     train_acc = accuracy_score(y_train, y_train_pred)
#
#     # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡ test
#     y_test_pred = model.predict(X_test_scaled)
#     test_acc = accuracy_score(y_test, y_test_pred)
#
#     # Ø§Ø®ØªÙ„Ø§Ù performance
#     acc_diff = train_acc - test_acc
#
#     overfitting_results[name] = {
#         'train_accuracy': train_acc,
#         'test_accuracy': test_acc,
#         'accuracy_difference': acc_diff
#     }
#
#     print(f"{name}:")
#     print(f"  Ø¯Ù‚Øª Ø¢Ù…ÙˆØ²Ø´: {train_acc:.4f}")
#     print(f"  Ø¯Ù‚Øª ØªØ³Øª: {test_acc:.4f}")
#     print(f"  Ø§Ø®ØªÙ„Ø§Ù: {acc_diff:.4f} {'(Ù…Ù…Ú©Ù† Ø§Ø³Øª overfit Ø¨Ø§Ø´Ø¯)' if acc_diff > 0.05 else ''}")
#     print("  " + "-" * 40)
#
# # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ù…ØªÙ‚Ø§Ø¨Ù„ Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø¨ÛŒØ´ØªØ±
# print("\n" + "=" * 60)
# print("Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ù…ØªÙ‚Ø§Ø¨Ù„ (Cross-Validation)")
# print("=" * 60)
#
# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
#
# for name, model in models.items():
#     cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='accuracy')
#     print(f"{name}:")
#     print(f"  Ø¯Ù‚Øª CV: {cv_scores.mean():.4f} (Â±{cv_scores.std() * 2:.4f})")
#     print(f"  Ù…Ù‚Ø§Ø¯ÛŒØ± CV: {[f'{score:.4f}' for score in cv_scores]}")
#
# # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ø®ØªÛŒ
# print("\n" + "=" * 60)
# print("Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø¯Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ø®ØªÛŒ")
# print("=" * 60)
#
# tree_based_models = {
#     'Decision Tree': models.get('Decision Tree'),
#     'Random Forest': models.get('Random Forest'),
#     'Gradient Boosting': models.get('Gradient Boosting'),
#     'Xgboost': models.get('Xgboost')
# }
#
# for name, model in tree_based_models.items():
#     if model and hasattr(model, 'feature_importances_'):
#         print(f"\n{name} - 10 ÙˆÛŒÚ˜Ú¯ÛŒ Ù…Ù‡Ù…:")
#         feature_importance = pd.DataFrame({
#             'feature': X.columns,
#             'importance': model.feature_importances_
#         })
#         feature_importance = feature_importance.sort_values('importance', ascending=False).head(10)
#
#         plt.figure(figsize=(10, 6))
#         sns.barplot(x='importance', y='feature', data=feature_importance)
#         plt.title(f'ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… - {name}')
#         plt.tight_layout()
#         plt.show()
#
#         print(feature_importance[['feature', 'importance']].to_string(index=False))
#
# # Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù†Ù‡Ø§ÛŒÛŒ
# print("\n" + "=" * 60)
# print("Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡")
# print("=" * 60)
#
# # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ F1-score (Ù…Ø¹ÛŒØ§Ø± Ø¨Ù‡ØªØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…ØªÙˆØ§Ø²Ù†)
# best_model_name = results_df.index[0]
# best_f1_score = results_df.iloc[0]['f1_score']
#
# print(f"Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ù‚Øª: {best_model_name} (Ø¯Ù‚Øª: {results_df.iloc[0]['accuracy']:.4f})")
# print(f"Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ F1-score: {best_model_name} (F1-score: {best_f1_score:.4f})")
#
# # Ø¨Ø±Ø±Ø³ÛŒ overfitting Ø¨Ø±Ø§ÛŒ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„
# best_model_overfitting = overfitting_results[best_model_name]
# acc_diff = best_model_overfitting['accuracy_difference']
#
# if acc_diff > 0.05:
#     print(f"âš ï¸  Ù‡Ø´Ø¯Ø§Ø±: Ù…Ø¯Ù„ {best_model_name} Ù…Ù…Ú©Ù† Ø§Ø³Øª overfit Ø¨Ø§Ø´Ø¯ (Ø§Ø®ØªÙ„Ø§Ù Ø¯Ù‚Øª: {acc_diff:.4f})")
#     print("Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Regularization ÛŒØ§ Ú©Ø§Ù‡Ø´ Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ Ù…Ø¯Ù„")
# else:
#     print(f"âœ… Ù…Ø¯Ù„ {best_model_name} Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…ØªØ¹Ø§Ø¯Ù„ÛŒ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡ train Ùˆ test Ø¯Ø§Ø±Ø¯")
#
# print("\n" + "=" * 60)
# print("Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ù†Ù‡Ø§ÛŒÛŒ")
# print("=" * 60)
#
# if best_f1_score > 0.95 and acc_diff <= 0.05:
#     print("ğŸ‰ Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ Ø¨Ø³ÛŒØ§Ø± Ø®ÙˆØ¨ Ø¹Ù…Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± production Ù…Ù†Ø§Ø³Ø¨ Ø§Ø³Øª")
#     print(f"Ù…Ø¯Ù„ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ: {best_model_name}")
# else:
#     print("ğŸ” Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙ†Ø¸ÛŒÙ… Ø¨ÛŒØ´ØªØ± Ù…Ø¯Ù„ ÛŒØ§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù…Ù‚Ø§Ø¨Ù„Ù‡ Ø¨Ø§ overfitting Ø¯Ø§Ø±ÛŒÙ…")
#     print("Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª:")
#     print("- Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² regularization Ø¯Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§")
#     print("- Ú©Ø§Ù‡Ø´ ØªØ¹Ø¯Ø§Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (feature selection)")
#     print("- Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ")
#     print("- Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù…Ù‚Ø§Ø¨Ù„Ù‡ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…ØªÙˆØ§Ø²Ù†")
#
# # Ø°Ø®ÛŒØ±Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ù‡Ø§ÛŒÛŒ
# best_model = models[best_model_name]
# joblib.dump(best_model, 'models/best_model.joblib')
# joblib.dump(scaler, 'models/scaler.joblib')
# print(f"\nâœ… Ù…Ø¯Ù„ {best_model_name} Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
#
# # Ø¨Ø±Ø±Ø³ÛŒ Ø±Ø§Ø¨Ø·Ù‡ Ø¨ÛŒÙ† result Ùˆ Class/ASD
# print("Ø±Ø§Ø¨Ø·Ù‡ Ø¨ÛŒÙ† result Ùˆ Class/ASD:")
# print(pd.crosstab(df['result'], df['Class/ASD']))
#
# # Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ
# print(f"\nÙ‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨ÛŒÙ† result Ùˆ Class/ASD: {df['result'].corr(df['Class/ASD'])}")
#
# # Ø­Ø°Ù ÙˆÛŒÚ˜Ú¯ÛŒ result Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¬Ø¯Ø¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§
# X_new = df.drop(['Class/ASD', 'result'], axis=1)
# y_new = df['Class/ASD']
#
# # ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¬Ø¯Ø¯
# X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(
#     X_new, y_new, test_size=0.2, random_state=42, stratify=y_new
# )
#
# # Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø¯ÙˆÙ† ÙˆÛŒÚ˜Ú¯ÛŒ result

# Ø¨Ø±Ø±Ø³ÛŒ Ø¬Ø§Ù…Ø¹ Ø¯Ø§Ø¯Ù‡ Ùˆ Ø­Ù„ Ù…Ø´Ú©Ù„ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ Data Leakage
# import pandas as pd
# import numpy as np
# import matplotlib.pyplot as plt
# import seaborn as sns
# from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
# from sklearn.preprocessing import StandardScaler, LabelEncoder
# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, \
#     f1_score
# from sklearn.linear_model import LogisticRegression
# from sklearn.neighbors import KNeighborsClassifier
# from sklearn.svm import SVC
# from sklearn.tree import DecisionTreeClassifier
# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
# from xgboost import XGBClassifier
# import joblib
# import warnings
#
# warnings.filterwarnings('ignore')
#
# # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡ Ø§ØµÙ„ÛŒ
# df = pd.read_csv('Autism-Adult-Data.csv')
#
# print("=" * 60)
# print("Ø¨Ø±Ø±Ø³ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø¯Ø§Ø¯Ù‡ Ùˆ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø´Ú©ÙˆÚ©")
# print("=" * 60)
#
# # Ø¨Ø±Ø±Ø³ÛŒ Ø±Ø§Ø¨Ø·Ù‡ Ø¨ÛŒÙ† result Ùˆ Class/ASD
# print("ØªÙˆØ²ÛŒØ¹ result Ø¨Ø± Ø§Ø³Ø§Ø³ Class/ASD:")
# result_asd_crosstab = pd.crosstab(df['result'], df['Class/ASD'], margins=True)
# print(result_asd_crosstab)
#
# # Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨ÛŒÙ† result Ùˆ Ø³Ø§ÛŒØ± ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ
# numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
# if 'result' in numeric_cols and 'Class/ASD' in df.columns:
#     # ØªØ¨Ø¯ÛŒÙ„ Class/ASD Ø¨Ù‡ Ø¹Ø¯Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ
#     df_corr = df.copy()
#     le = LabelEncoder()
#     df_corr['Class/ASD_num'] = le.fit_transform(df_corr['Class/ASD'])
#
#     # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ
#     correlation = df_corr['result'].corr(df_corr['Class/ASD_num'])
#     print(f"\nÙ‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨ÛŒÙ† result Ùˆ Class/ASD: {correlation:.4f}")
#
# # Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
# print("\n" + "=" * 60)
# print("Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§")
# print("=" * 60)
#
# # Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ù‚Ø§Ø¯ÛŒØ± Ú¯Ù…Ø´Ø¯Ù‡
# df['age'].fillna(df['age'].median(), inplace=True)
# df['ethnicity'].fillna('Unknown', inplace=True)
# df['relation'].fillna('Unknown', inplace=True)
#
# # Ø­Ø°Ù Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ ØºÛŒØ±Ø¶Ø±ÙˆØ±ÛŒ
# df.drop('age_desc', axis=1, inplace=True)
#
# # ØªØ¨Ø¯ÛŒÙ„ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ú©ÛŒÙÛŒ Ø¨Ù‡ Ø¹Ø¯Ø¯ÛŒ
# binary_cols = ['gender', 'jundice', 'austim', 'used_app_before', 'Class/ASD']
# le = LabelEncoder()
# for col in binary_cols:
#     if col in df.columns:
#         df[col] = le.fit_transform(df[col])
#
# # One-Hot Encoding Ø¨Ø±Ø§ÛŒ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ
# categorical_cols = ['ethnicity', 'contry_of_res', 'relation']
# df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)
#
# print(f"Ø§Ø¨Ø¹Ø§Ø¯ Ø¯Ø§Ø¯Ù‡ Ù¾Ø³ Ø§Ø² Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´: {df.shape}")
#
# # Ø¯Ùˆ Ø³Ù†Ø§Ø±ÛŒÙˆ Ù…Ø®ØªÙ„Ù Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ
# print("\n" + "=" * 60)
# print("Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¯Ùˆ Ø³Ù†Ø§Ø±ÛŒÙˆ: Ø¨Ø§ Ùˆ Ø¨Ø¯ÙˆÙ† ÙˆÛŒÚ˜Ú¯ÛŒ result")
# print("=" * 60)
#
# scenarios = {
#     'Ø¨Ø§ ÙˆÛŒÚ˜Ú¯ÛŒ result': df.drop('Class/ASD', axis=1),
#     'Ø¨Ø¯ÙˆÙ† ÙˆÛŒÚ˜Ú¯ÛŒ result': df.drop(['Class/ASD', 'result'], axis=1)
# }
#
# results_comparison = {}
#
# for scenario_name, X in scenarios.items():
#     print(f"\n{'=' * 30} {scenario_name} {'=' * 30}")
#
#     y = df['Class/ASD']
#
#     # ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
#     X_train, X_test, y_train, y_test = train_test_split(
#         X, y, test_size=0.2, random_state=42, stratify=y
#     )
#
#     # Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ
#     scaler = StandardScaler()
#     X_train_scaled = scaler.fit_transform(X_train)
#     X_test_scaled = scaler.transform(X_test)
#
#     # ØªØ¹Ø±ÛŒÙ Ù…Ø¯Ù„â€ŒÙ‡Ø§
#     models = {
#         "Logistic Regression": LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000),
#         "K-Nearest Neighbors": KNeighborsClassifier(),
#         "Support Vector Machine": SVC(random_state=42, class_weight='balanced', probability=True),
#         "Decision Tree": DecisionTreeClassifier(random_state=42, class_weight='balanced', max_depth=5),
#         "Random Forest": RandomForestClassifier(random_state=42, class_weight='balanced', n_estimators=100,
#                                                 max_depth=5),
#         "Gradient Boosting": GradientBoostingClassifier(random_state=42, n_estimators=100, max_depth=3),
#         "XGBoost": XGBClassifier(random_state=42, eval_metric='logloss', max_depth=3)
#     }
#
#     scenario_results = {}
#
#     for name, model in models.items():
#         # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
#         model.fit(X_train_scaled, y_train)
#
#         # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
#         y_pred = model.predict(X_test_scaled)
#
#         # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
#         acc = accuracy_score(y_test, y_pred)
#         prec = precision_score(y_test, y_pred)
#         rec = recall_score(y_test, y_pred)
#         f1 = f1_score(y_test, y_pred)
#
#         scenario_results[name] = {
#             'accuracy': acc,
#             'precision': prec,
#             'recall': rec,
#             'f1_score': f1
#         }
#
#         # Ø¨Ø±Ø±Ø³ÛŒ overfitting
#         y_train_pred = model.predict(X_train_scaled)
#         train_acc = accuracy_score(y_train, y_train_pred)
#         acc_diff = train_acc - acc
#
#         print(f"{name}:")
#         print(f"  Ø¯Ù‚Øª (ØªØ³Øª): {acc:.4f}, Ø¯Ù‚Øª (Ø¢Ù…ÙˆØ²Ø´): {train_acc:.4f}, Ø§Ø®ØªÙ„Ø§Ù: {acc_diff:.4f}")
#         if acc_diff > 0.05:
#             print("  âš ï¸  Ø§Ø­ØªÙ…Ø§Ù„ overfitting")
#
#     # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ Ø§ÛŒÙ† Ø³Ù†Ø§Ø±ÛŒÙˆ
#     results_comparison[scenario_name] = scenario_results
#
# # Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù†ØªØ§ÛŒØ¬ Ø¯Ùˆ Ø³Ù†Ø§Ø±ÛŒÙˆ
# print("\n" + "=" * 60)
# print("Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¬Ø§Ù…Ø¹ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¯Ø± Ø¯Ùˆ Ø³Ù†Ø§Ø±ÛŒÙˆ")
# print("=" * 60)
#
# for model_name in models.keys():
#     print(f"\n{model_name}:")
#     print("-" * len(model_name))
#
#     for scenario_name in scenarios.keys():
#         if model_name in results_comparison[scenario_name]:
#             results = results_comparison[scenario_name][model_name]
#             print(f"  {scenario_name}:")
#             print(f"    Ø¯Ù‚Øª: {results['accuracy']:.4f}, F1-score: {results['f1_score']:.4f}")
#
# # Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ù‡ØªØ±ÛŒÙ† Ø³Ù†Ø§Ø±ÛŒÙˆ Ùˆ Ù…Ø¯Ù„
# print("\n" + "=" * 60)
# print("Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø¹ÛŒØ§Ø± F1-score")
# print("=" * 60)
#
# best_scenario = None
# best_model_name = None
# best_f1 = 0
#
# for scenario_name, scenario_results in results_comparison.items():
#     for model_name, results in scenario_results.items():
#         if results['f1_score'] > best_f1:
#             best_f1 = results['f1_score']
#             best_model_name = model_name
#             best_scenario = scenario_name
#
# print(f"Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„: {best_model_name}")
# print(f"Ø¨Ù‡ØªØ±ÛŒÙ† Ø³Ù†Ø§Ø±ÛŒÙˆ: {best_scenario}")
# print(f"best F1-score: {best_f1:.4f}")
#
# # Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„
# print("\n" + "=" * 60)
# print("Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„")
# print("=" * 60)
#
# # Ø§Ù†ØªØ®Ø§Ø¨ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¨Ù‡ØªØ±ÛŒÙ† Ø³Ù†Ø§Ø±ÛŒÙˆ
# if best_scenario == 'Ø¨Ø§ ÙˆÛŒÚ˜Ú¯ÛŒ result':
#     X_final = df.drop('Class/ASD', axis=1)
# else:
#     X_final = df.drop(['Class/ASD', 'result'], axis=1)
#
# y_final = df['Class/ASD']
#
# # ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
# X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(
#     X_final, y_final, test_size=0.2, random_state=42, stratify=y_final
# )
#
# # Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ
# scaler_final = StandardScaler()
# X_train_final_scaled = scaler_final.fit_transform(X_train_final)
# X_test_final_scaled = scaler_final.transform(X_test_final)
#
# # Ø¢Ù…ÙˆØ²Ø´ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„
# if best_model_name == "Logistic Regression":
#     best_model = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000)
# elif best_model_name == "K-Nearest Neighbors":
#     best_model = KNeighborsClassifier()
# elif best_model_name == "Support Vector Machine":
#     best_model = SVC(random_state=42, class_weight='balanced', probability=True)
# elif best_model_name == "Decision Tree":
#     best_model = DecisionTreeClassifier(random_state=42, class_weight='balanced', max_depth=5)
# elif best_model_name == "Random Forest":
#     best_model = RandomForestClassifier(random_state=42, class_weight='balanced', n_estimators=100, max_depth=5)
# elif best_model_name == "Gradient Boosting":
#     best_model = GradientBoostingClassifier(random_state=42, n_estimators=100, max_depth=3)
# elif best_model_name == "XGBoost":
#     best_model = XGBClassifier(random_state=42, eval_metric='logloss', max_depth=3)
#
# best_model.fit(X_train_final_scaled, y_train_final)
#
# # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
# y_pred_final = best_model.predict(X_test_final_scaled)
# final_acc = accuracy_score(y_test_final, y_pred_final)
# final_f1 = f1_score(y_test_final, y_pred_final)
#
# print(f"Ø¯Ù‚Øª Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„: {final_acc:.4f}")
# print(f"F1-score Ù†Ù‡Ø§ÛŒÛŒ: {final_f1:.4f}")
#
# # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ùˆ scaler
# joblib.dump(best_model, 'best_model_final.joblib')
# joblib.dump(scaler_final, 'scaler_final.joblib')
#
# # Ø°Ø®ÛŒØ±Ù‡ Ù†Ø§Ù… ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
# feature_names = list(X_final.columns)
# joblib.dump(feature_names, 'feature_names_final.joblib')
#
# print("\nÙ…Ø¯Ù„ØŒ scaler Ùˆ Ù†Ø§Ù… ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.")
#
# # ØªØ­Ù„ÛŒÙ„ Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (Ø§Ú¯Ø± Ù…Ø¯Ù„ Ø¯Ø±Ø®ØªÛŒ Ø§Ø³Øª)
# if hasattr(best_model, 'feature_importances_'):
#     print("\n" + "=" * 60)
#     print("ØªØ­Ù„ÛŒÙ„ Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø¯Ø± Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„")
#     print("=" * 60)
#
#     feature_importance = pd.DataFrame({
#         'feature': X_final.columns,
#         'importance': best_model.feature_importances_
#     })
#     feature_importance = feature_importance.sort_values('importance', ascending=False).head(10)
#
#     plt.figure(figsize=(10, 6))
#     sns.barplot(x='importance', y='feature', data=feature_importance)
#     plt.title(f'ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… - {best_model_name}')
#     plt.tight_layout()
#     plt.show()
#
#     print("Ø¯Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒ Ù…Ù‡Ù…:")
#     print(feature_importance[['feature', 'importance']].to_string(index=False))
#
# print("\n" + "=" * 60)
# print("Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ù†Ù‡Ø§ÛŒÛŒ")
# print("=" * 60)
#
# if best_scenario == 'Ø¨Ø§ ÙˆÛŒÚ˜Ú¯ÛŒ result' and best_f1 > 0.95:
#     print("âš ï¸  Ù‡Ø´Ø¯Ø§Ø±: Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ø§Ø² ÙˆÛŒÚ˜Ú¯ÛŒ result Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø§Ø¹Ø« data leakage Ø´ÙˆØ¯!")
#     print("Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯: Ø¯Ø± Ù…Ø­ÛŒØ· production Ø§Ø² Ø³Ù†Ø§Ø±ÛŒÙˆÛŒ Ø¨Ø¯ÙˆÙ† ÙˆÛŒÚ˜Ú¯ÛŒ result Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.")
# elif best_f1 > 0.85:
#     print("âœ… Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø®ÙˆØ¨ÛŒ Ø¯Ø§Ø±Ø¯ Ùˆ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± production Ù…Ù†Ø§Ø³Ø¨ Ø§Ø³Øª.")
# else:
#     print("ğŸ” Ù…Ø¯Ù„ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ø§Ø±Ø¯. Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ø§Ø² ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:")
#     print("   - ØªÙ†Ø¸ÛŒÙ… Ù‡ÛŒÙ¾Ø±Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§")
#     print("   - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù…Ù‚Ø§Ø¨Ù„Ù‡ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…ØªÙˆØ§Ø²Ù†")
#     print("   - Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ")
#
# print(f"\nØ¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ù†Ù‡Ø§ÛŒÛŒ: {best_model_name}")
# print(f"Ø³Ù†Ø§Ø±ÛŒÙˆÛŒ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ: {best_scenario}")


# # Ø¨Ø±Ø±Ø³ÛŒ Ø¬Ø§Ù…Ø¹ Ø¯Ø§Ø¯Ù‡ Ùˆ Ø­Ù„ Ù…Ø´Ú©Ù„ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ Data Leakage
import pandas as pd
# import numpy as np
# import matplotlib.pyplot as plt
# import seaborn as sns
# from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
# from sklearn.preprocessing import StandardScaler, LabelEncoder
# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, \
#     f1_score
# from sklearn.linear_model import LogisticRegression
# from sklearn.neighbors import KNeighborsClassifier
# from sklearn.svm import SVC
# from sklearn.tree import DecisionTreeClassifier
# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
# from xgboost import XGBClassifier
# import joblib
# import warnings
#
# warnings.filterwarnings('ignore')
#
# # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡ Ø§ØµÙ„ÛŒ
df = pd.read_csv('Autism-Adult-Data.csv')
#
# print("=" * 60)
# print("Ø¨Ø±Ø±Ø³ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø¯Ø§Ø¯Ù‡ Ùˆ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø´Ú©ÙˆÚ©")
# print("=" * 60)
#
# # Ø¨Ø±Ø±Ø³ÛŒ Ø±Ø§Ø¨Ø·Ù‡ Ø¨ÛŒÙ† result Ùˆ Class/ASD
# print("ØªÙˆØ²ÛŒØ¹ result Ø¨Ø± Ø§Ø³Ø§Ø³ Class/ASD:")
# result_asd_crosstab = pd.crosstab(df['result'], df['Class/ASD'], margins=True)
# print(result_asd_crosstab)
#
# # Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨ÛŒÙ† result Ùˆ Ø³Ø§ÛŒØ± ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ
# numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
# if 'result' in numeric_cols and 'Class/ASD' in df.columns:
#     # ØªØ¨Ø¯ÛŒÙ„ Class/ASD Ø¨Ù‡ Ø¹Ø¯Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ
#     df_corr = df.copy()
#     le = LabelEncoder()
#     df_corr['Class/ASD_num'] = le.fit_transform(df_corr['Class/ASD'])
#
#     # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ
#     correlation = df_corr['result'].corr(df_corr['Class/ASD_num'])
#     print(f"\nÙ‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨ÛŒÙ† result Ùˆ Class/ASD: {correlation:.4f}")
#
# # Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
# print("\n" + "=" * 60)
# print("Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§")
# print("=" * 60)
#
# # Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ù‚Ø§Ø¯ÛŒØ± Ú¯Ù…Ø´Ø¯Ù‡
# df['age'].fillna(df['age'].median(), inplace=True)
# df['ethnicity'].fillna('Unknown', inplace=True)
# df['relation'].fillna('Unknown', inplace=True)
#
# # Ø­Ø°Ù Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ ØºÛŒØ±Ø¶Ø±ÙˆØ±ÛŒ
# df.drop('age_desc', axis=1, inplace=True)
#
# # ØªØ¨Ø¯ÛŒÙ„ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ú©ÛŒÙÛŒ Ø¨Ù‡ Ø¹Ø¯Ø¯ÛŒ
# binary_cols = ['gender', 'jundice', 'austim', 'used_app_before', 'Class/ASD']
# le = LabelEncoder()
# for col in binary_cols:
#     if col in df.columns:
#         df[col] = le.fit_transform(df[col])
#
# # One-Hot Encoding Ø¨Ø±Ø§ÛŒ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ
# categorical_cols = ['ethnicity', 'contry_of_res', 'relation']
# df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)
#
# print(f"Ø§Ø¨Ø¹Ø§Ø¯ Ø¯Ø§Ø¯Ù‡ Ù¾Ø³ Ø§Ø² Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´: {df.shape}")
#
# # Ø¯Ùˆ Ø³Ù†Ø§Ø±ÛŒÙˆ Ù…Ø®ØªÙ„Ù Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ
# print("\n" + "=" * 60)
# print("Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¯Ùˆ Ø³Ù†Ø§Ø±ÛŒÙˆ: Ø¨Ø§ Ùˆ Ø¨Ø¯ÙˆÙ† ÙˆÛŒÚ˜Ú¯ÛŒ result")
# print("=" * 60)
#
# scenarios = {
#     'Ø¨Ø§ ÙˆÛŒÚ˜Ú¯ÛŒ result': df.drop('Class/ASD', axis=1),
#     'Ø¨Ø¯ÙˆÙ† ÙˆÛŒÚ˜Ú¯ÛŒ result': df.drop(['Class/ASD', 'result'], axis=1)
# }
#
# results_comparison = {}
#
# for scenario_name, X in scenarios.items():
#     print(f"\n{'=' * 30} {scenario_name} {'=' * 30}")
#
#     y = df['Class/ASD']
#
#     # ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
#     X_train, X_test, y_train, y_test = train_test_split(
#         X, y, test_size=0.2, random_state=42, stratify=y
#     )
#
#     # Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ
#     scaler = StandardScaler()
#     X_train_scaled = scaler.fit_transform(X_train)
#     X_test_scaled = scaler.transform(X_test)
#
#     # ØªØ¹Ø±ÛŒÙ Ù…Ø¯Ù„â€ŒÙ‡Ø§
#     models = {
#         "Logistic Regression": LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000),
#         "K-Nearest Neighbors": KNeighborsClassifier(),
#         "Support Vector Machine": SVC(random_state=42, class_weight='balanced', probability=True),
#         "Decision Tree": DecisionTreeClassifier(random_state=42, class_weight='balanced', max_depth=5),
#         "Random Forest": RandomForestClassifier(random_state=42, class_weight='balanced', n_estimators=100,
#                                                 max_depth=5),
#         "Gradient Boosting": GradientBoostingClassifier(random_state=42, n_estimators=100, max_depth=3),
#         "XGBoost": XGBClassifier(random_state=42, eval_metric='logloss', max_depth=3)
#     }
#
#     scenario_results = {}
#
#     for name, model in models.items():
#         # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
#         model.fit(X_train_scaled, y_train)
#
#         # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
#         y_pred = model.predict(X_test_scaled)
#
#         # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
#         acc = accuracy_score(y_test, y_pred)
#         prec = precision_score(y_test, y_pred)
#         rec = recall_score(y_test, y_pred)
#         f1 = f1_score(y_test, y_pred)
#
#         scenario_results[name] = {
#             'accuracy': acc,
#             'precision': prec,
#             'recall': rec,
#             'f1_score': f1
#         }
#
#         # Ø¨Ø±Ø±Ø³ÛŒ overfitting
#         y_train_pred = model.predict(X_train_scaled)
#         train_acc = accuracy_score(y_train, y_train_pred)
#         acc_diff = train_acc - acc
#
#         print(f"{name}:")
#         print(f"  Ø¯Ù‚Øª (ØªØ³Øª): {acc:.4f}, Ø¯Ù‚Øª (Ø¢Ù…ÙˆØ²Ø´): {train_acc:.4f}, Ø§Ø®ØªÙ„Ø§Ù: {acc_diff:.4f}")
#         if acc_diff > 0.05:
#             print("  âš ï¸  Ø§Ø­ØªÙ…Ø§Ù„ overfitting")
#
#     # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ Ø§ÛŒÙ† Ø³Ù†Ø§Ø±ÛŒÙˆ
#     results_comparison[scenario_name] = scenario_results
#
# # Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù†ØªØ§ÛŒØ¬ Ø¯Ùˆ Ø³Ù†Ø§Ø±ÛŒÙˆ
# print("\n" + "=" * 60)
# print("Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¬Ø§Ù…Ø¹ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¯Ø± Ø¯Ùˆ Ø³Ù†Ø§Ø±ÛŒÙˆ")
# print("=" * 60)
#
# for model_name in models.keys():
#     print(f"\n{model_name}:")
#     print("-" * len(model_name))
#
#     for scenario_name in scenarios.keys():
#         if model_name in results_comparison[scenario_name]:
#             results = results_comparison[scenario_name][model_name]
#             print(f"  {scenario_name}:")
#             print(f"    Ø¯Ù‚Øª: {results['accuracy']:.4f}, F1-score: {results['f1_score']:.4f}")
#
# # Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ù‡ØªØ±ÛŒÙ† Ø³Ù†Ø§Ø±ÛŒÙˆ Ùˆ Ù…Ø¯Ù„
# print("\n" + "=" * 60)
# print("Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø¹ÛŒØ§Ø± F1-score")
# print("=" * 60)
#
# best_scenario = None
# best_model_name = None
# best_f1 = 0
#
# for scenario_name, scenario_results in results_comparison.items():
#     for model_name, results in scenario_results.items():
#         if results['f1_score'] > best_f1:
#             best_f1 = results['f1_score']
#             best_model_name = model_name
#             best_scenario = scenario_name
#
# print(f"Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„: {best_model_name}")
# print(f"Ø¨Ù‡ØªØ±ÛŒÙ† Ø³Ù†Ø§Ø±ÛŒÙˆ: {best_scenario}")
# print(f"best F1-score: {best_f1:.4f}")
#
# # Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„
# print("\n" + "=" * 60)
# print("Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„")
# print("=" * 60)
#
# # Ø§Ù†ØªØ®Ø§Ø¨ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¨Ù‡ØªØ±ÛŒÙ† Ø³Ù†Ø§Ø±ÛŒÙˆ
# if best_scenario == 'Ø¨Ø§ ÙˆÛŒÚ˜Ú¯ÛŒ result':
#     X_final = df.drop('Class/ASD', axis=1)
# else:
#     X_final = df.drop(['Class/ASD', 'result'], axis=1)
#
# y_final = df['Class/ASD']
#
# # ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
# X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(
#     X_final, y_final, test_size=0.2, random_state=42, stratify=y_final
# )
#
# # Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ
# scaler_final = StandardScaler()
# X_train_final_scaled = scaler_final.fit_transform(X_train_final)
# X_test_final_scaled = scaler_final.transform(X_test_final)
#
# # Ø¢Ù…ÙˆØ²Ø´ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„
# if best_model_name == "Logistic Regression":
#     best_model = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000)
# elif best_model_name == "K-Nearest Neighbors":
#     best_model = KNeighborsClassifier()
# elif best_model_name == "Support Vector Machine":
#     best_model = SVC(random_state=42, class_weight='balanced', probability=True)
# elif best_model_name == "Decision Tree":
#     best_model = DecisionTreeClassifier(random_state=42, class_weight='balanced', max_depth=5)
# elif best_model_name == "Random Forest":
#     best_model = RandomForestClassifier(random_state=42, class_weight='balanced', n_estimators=100, max_depth=5)
# elif best_model_name == "Gradient Boosting":
#     best_model = GradientBoostingClassifier(random_state=42, n_estimators=100, max_depth=3)
# elif best_model_name == "XGBoost":
#     best_model = XGBClassifier(random_state=42, eval_metric='logloss', max_depth=3)
#
# best_model.fit(X_train_final_scaled, y_train_final)
#
# # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
# y_pred_final = best_model.predict(X_test_final_scaled)
# final_acc = accuracy_score(y_test_final, y_pred_final)
# final_f1 = f1_score(y_test_final, y_pred_final)
#
# print(f"Ø¯Ù‚Øª Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„: {final_acc:.4f}")
# print(f"F1-score Ù†Ù‡Ø§ÛŒÛŒ: {final_f1:.4f}")
#
# # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ùˆ scaler
# joblib.dump(best_model, 'best_model_final.joblib')
# joblib.dump(scaler_final, 'scaler_final.joblib')
#
# # Ø°Ø®ÛŒØ±Ù‡ Ù†Ø§Ù… ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
# feature_names = list(X_final.columns)
# joblib.dump(feature_names, 'feature_names_final.joblib')
#
# print("\nÙ…Ø¯Ù„ØŒ scaler Ùˆ Ù†Ø§Ù… ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.")
#
# # ØªØ­Ù„ÛŒÙ„ Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (Ø§Ú¯Ø± Ù…Ø¯Ù„ Ø¯Ø±Ø®ØªÛŒ Ø§Ø³Øª)
# if hasattr(best_model, 'feature_importances_'):
#     print("\n" + "=" * 60)
#     print("ØªØ­Ù„ÛŒÙ„ Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø¯Ø± Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„")
#     print("=" * 60)
#
#     feature_importance = pd.DataFrame({
#         'feature': X_final.columns,
#         'importance': best_model.feature_importances_
#     })
#     feature_importance = feature_importance.sort_values('importance', ascending=False).head(10)
#
#     plt.figure(figsize=(10, 6))
#     sns.barplot(x='importance', y='feature', data=feature_importance)
#     plt.title(f'ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… - {best_model_name}')
#     plt.tight_layout()
#     plt.show()
#
#     print("Ø¯Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒ Ù…Ù‡Ù…:")
#     print(feature_importance[['feature', 'importance']].to_string(index=False))
#
# print("\n" + "=" * 60)
# print("Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ù†Ù‡Ø§ÛŒÛŒ")
# print("=" * 60)
#
# if best_scenario == 'Ø¨Ø§ ÙˆÛŒÚ˜Ú¯ÛŒ result' and best_f1 > 0.95:
#     print("âš ï¸  Ù‡Ø´Ø¯Ø§Ø±: Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ø§Ø² ÙˆÛŒÚ˜Ú¯ÛŒ result Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø§Ø¹Ø« data leakage Ø´ÙˆØ¯!")
#     print("Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯: Ø¯Ø± Ù…Ø­ÛŒØ· production Ø§Ø² Ø³Ù†Ø§Ø±ÛŒÙˆÛŒ Ø¨Ø¯ÙˆÙ† ÙˆÛŒÚ˜Ú¯ÛŒ result Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.")
# elif best_f1 > 0.85:
#     print("âœ… Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø®ÙˆØ¨ÛŒ Ø¯Ø§Ø±Ø¯ Ùˆ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± production Ù…Ù†Ø§Ø³Ø¨ Ø§Ø³Øª.")
# else:
#     print("ğŸ” Ù…Ø¯Ù„ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ø§Ø±Ø¯. Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ø§Ø² ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:")
#     print("   - ØªÙ†Ø¸ÛŒÙ… Ù‡ÛŒÙ¾Ø±Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§")
#     print("   - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù…Ù‚Ø§Ø¨Ù„Ù‡ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…ØªÙˆØ§Ø²Ù†")
#     print("   - Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ")
#
# print(f"\nØ¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ù†Ù‡Ø§ÛŒÛŒ: {best_model_name}")
# print(f"Ø³Ù†Ø§Ø±ÛŒÙˆÛŒ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ: {best_scenario}")

# Ú©Ø¯ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ ÙˆØ§Ù‚Ø¹ÛŒ
# Ú©Ø¯ Ú©Ø§Ù…Ù„ Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø¯ÙˆÙ† Data Leakage
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import StandardScaler
import warnings

warnings.filterwarnings('ignore')

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…ÙˆØ¯Ø§Ø±
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['font.size'] = 12
sns.set_palette("husl")

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ³Øª
df = pd.read_csv('Autism-Adult-Data.csv')

# Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ (Ù…Ø´Ø§Ø¨Ù‡ Ù‚Ø¨Ù„)
df['age'].fillna(df['age'].median(), inplace=True)
df['ethnicity'].fillna('Unknown', inplace=True)
df['relation'].fillna('Unknown', inplace=True)
df.drop('age_desc', axis=1, inplace=True)

from sklearn.preprocessing import LabelEncoder

binary_cols = ['gender', 'jundice', 'austim', 'used_app_before', 'Class/ASD']
le = LabelEncoder()
for col in binary_cols:
    df[col] = le.fit_transform(df[col])

categorical_cols = ['ethnicity', 'contry_of_res', 'relation']
df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

# Ø¢Ù…Ø§Ø¯Ù‡ Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ³Øª
X_with_result = df.drop('Class/ASD', axis=1)
X_without_result = df.drop(['Class/ASD', 'result'], axis=1)
y = df['Class/ASD']

# ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_without_result, y, test_size=0.2, random_state=42, stratify=y)

# Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ
scaler = StandardScaler()
X_test_scaled = scaler.fit_transform(X_test)

print("=" * 60)
print("Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¬Ø§Ù…Ø¹ Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡")
print("=" * 60)

# Ù„ÛŒØ³Øª Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡
model_files = {
    'final_model': 'best_model_final.joblib',
    'real_model': 'best_model_real.joblib',
    'logistic_regression': 'models/logistic_regression_model.joblib',
    'random_forest': 'models/random_forest_model.joblib',
    'gradient_boosting': 'models/gradient_boosting_model.joblib',
    'xgboost': 'models/xgboost_model.joblib'
}

results = []

# ØªØ³Øª Ù‡Ø± Ù…Ø¯Ù„
for model_name, file_path in model_files.items():
    try:
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„
        model = joblib.load(file_path)

        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
        if 'result' in model_name:
            # Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ø§ result Ø¢Ù…ÙˆØ²Ø´ Ø¯ÛŒØ¯Ù‡â€ŒØ§Ù†Ø¯ØŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡ Ù…ØªÙØ§ÙˆØª Ø¯Ø§Ø±ÛŒÙ…
            X_test_special = X_with_result.iloc[X_test.index]
            X_test_special_scaled = scaler.transform(X_test_special)
            y_pred = model.predict(X_test_special_scaled)
        else:
            # Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø¯ÙˆÙ† result
            y_pred = model.predict(X_test_scaled)

        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§
        acc = accuracy_score(y_test, y_pred)
        prec = precision_score(y_test, y_pred)
        rec = recall_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)

        results.append({
            'model': model_name,
            'accuracy': acc,
            'precision': prec,
            'recall': rec,
            'f1_score': f1
        })

        print(f"{model_name}: Ø¯Ù‚Øª = {acc:.4f}, F1-score = {f1:.4f}")

    except FileNotFoundError:
        print(f"ÙØ§ÛŒÙ„ {file_path} ÛŒØ§ÙØª Ù†Ø´Ø¯")
    except Exception as e:
        print(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ {model_name}: {str(e)}")

# Ø§ÛŒØ¬Ø§Ø¯ DataFrame Ø§Ø² Ù†ØªØ§ÛŒØ¬
results_df = pd.DataFrame(results)
results_df = results_df.sort_values('f1_score', ascending=False)

print("\n" + "=" * 60)
print("Ø±Ø¯Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ F1-Score")
print("=" * 60)
print(results_df[['model', 'accuracy', 'f1_score']].round(4))

# Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡
fig, axes = plt.subplots(2, 2, figsize=(15, 12))
fig.suptitle('Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¬Ø§Ù…Ø¹ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù', fontsize=16, fontweight='bold')

# Ù†Ù…ÙˆØ¯Ø§Ø± Ø¯Ù‚Øª
axes[0, 0].barh(results_df['model'], results_df['accuracy'], color='skyblue')
axes[0, 0].set_title('Ø¯Ù‚Øª (Accuracy) Ù…Ø¯Ù„â€ŒÙ‡Ø§')
axes[0, 0].set_xlabel('Ø¯Ù‚Øª')
axes[0, 0].set_xlim(0, 1)

# Ù†Ù…ÙˆØ¯Ø§Ø± F1-Score
axes[0, 1].barh(results_df['model'], results_df['f1_score'], color='lightgreen')
axes[0, 1].set_title('F1-Score Ù…Ø¯Ù„â€ŒÙ‡Ø§')
axes[0, 1].set_xlabel('F1-Score')
axes[0, 1].set_xlim(0, 1)

# Ù†Ù…ÙˆØ¯Ø§Ø± Precision
axes[1, 0].barh(results_df['model'], results_df['precision'], color='lightcoral')
axes[1, 0].set_title('Precision Ù…Ø¯Ù„â€ŒÙ‡Ø§')
axes[1, 0].set_xlabel('Precision')
axes[1, 0].set_xlim(0, 1)

# Ù†Ù…ÙˆØ¯Ø§Ø± Recall
axes[1, 1].barh(results_df['model'], results_df['recall'], color='gold')
axes[1, 1].set_title('Recall Ù…Ø¯Ù„â€ŒÙ‡Ø§')
axes[1, 1].set_xlabel('Recall')
axes[1, 1].set_xlim(0, 1)

plt.tight_layout()
plt.show()

# Ù†Ù…ÙˆØ¯Ø§Ø± Radar Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‡Ù…Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§
fig = plt.figure(figsize=(10, 10))
ax = fig.add_subplot(111, polar=True)

# Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø²ÙˆØ§ÛŒØ§
categories = ['Ø¯Ù‚Øª', 'Precision', 'Recall', 'F1-Score']
N = len(categories)
angles = [n / float(N) * 2 * np.pi for n in range(N)]
angles += angles[:1]

# Ø±Ø³Ù… Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù…Ø¯Ù„
colors = plt.cm.viridis(np.linspace(0, 1, len(results_df)))

for idx, (_, row) in enumerate(results_df.iterrows()):
    values = [
        row['accuracy'],
        row['precision'],
        row['recall'],
        row['f1_score']
    ]
    values += values[:1]

    ax.plot(angles, values, color=colors[idx], linewidth=2, label=row['model'])
    ax.fill(angles, values, color=colors[idx], alpha=0.1)

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…ÙˆØ¯Ø§Ø±
ax.set_xticks(angles[:-1])
ax.set_xticklabels(categories)
ax.set_yticklabels([])
ax.set_title('Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¬Ø§Ù…Ø¹ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø§ Ù†Ù…ÙˆØ¯Ø§Ø± Radar', size=15, y=1.1)
ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))

plt.tight_layout()
plt.show()

# Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„
best_model_row = results_df.iloc[0]
best_model_name = best_model_row['model']
best_model_file = model_files[best_model_name]

print("\n" + "=" * 60)
print("Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ùˆ Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„")
print("=" * 60)
print(f"Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„: {best_model_name}")
print(f"Ø¯Ù‚Øª: {best_model_row['accuracy']:.4f}")
print(f"F1-Score: {best_model_row['f1_score']:.4f}")
print(f"Precision: {best_model_row['precision']:.4f}")
print(f"Recall: {best_model_row['recall']:.4f}")

# Ù‡Ø´Ø¯Ø§Ø± Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ data leakage
models_with_result = [name for name in results_df['model'] if 'result' in name]
if models_with_result:
    print(f"\nâš ï¸  Ù‡Ø´Ø¯Ø§Ø±: Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¯Ú†Ø§Ø± data leakage Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ù†Ø¯:")
    for model in models_with_result:
        print(f"   - {model}")

print("\nâœ… Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯: Ø§Ø² best_model_real.joblib Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯")
print("   Ø²ÛŒØ±Ø§ Ø¨Ø¯ÙˆÙ† data leakage Ø¢Ù…ÙˆØ²Ø´ Ø¯ÛŒØ¯Ù‡ Ùˆ Ø¹Ù…Ù„Ú©Ø±Ø¯ ÙˆØ§Ù‚Ø¹ÛŒ Ø¯Ø§Ø±Ø¯")

# Ù†Ù…Ø§ÛŒØ´ Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„
try:
    best_model = joblib.load(best_model_file)
    if hasattr(best_model, 'feature_importances_'):
        print("\n" + "=" * 60)
        print("Ø¯Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒ Ù…Ù‡Ù… Ø¯Ø± Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„")
        print("=" * 60)

        feature_importance = pd.DataFrame({
            'feature': X_without_result.columns,
            'importance': best_model.feature_importances_
        })
        feature_importance = feature_importance.sort_values('importance', ascending=False).head(10)

        plt.figure(figsize=(12, 8))
        sns.barplot(x='importance', y='feature', data=feature_importance)
        plt.title('Ø¯Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒ Ù…Ù‡Ù… Ø¯Ø± Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„')
        plt.tight_layout()
        plt.show()

        print(feature_importance[['feature', 'importance']].to_string(index=False))

except Exception as e:
    print(f"Ø®Ø·Ø§ Ø¯Ø± Ù†Ù…Ø§ÛŒØ´ Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§: {str(e)}")